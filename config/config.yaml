defaults:
  - model: Swin-T
  - _self_

trainer:
  num_epochs: 300
  warmup_steps: 20
  patience: 5

model:
  patch_size: 4
  num_heads: [3, 6, 12, 24]  # Number of attention heads
  window_size: 8  # Window size (root of patches in each window)
  dropout: 0.2  # MLP dropout probability
  num_classes: 100

optimizer:
  lr: 1e-3
  weight_decay: 0.05

criterion:
  label_smoothing: 0

data:
  train:
    batch_size: 32 
    shuffle: true
    persistent_workers: true
    num_workers: 4
    pin_memory: true
    
  valid:
    batch_size: 32 
    persistent_workers: true
    num_workers: 4
    pin_memory: true
